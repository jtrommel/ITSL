\documentclass{tufte-book}
\usepackage{graphicx}  % werken met figuren
\usepackage{gensymb} % werken met wetenschappelijke eenheden\usepackage{geometry}
\usepackage{changepage} % http://ctan.org/pkg/changepage
\usepackage[dutch,british]{babel} % instelling van de taal (woordsplitsing, spellingscontrole)
\usepackage[parfill]{parskip} % Paragrafen gescheiden door witte lijn en geen inspringing
\usepackage[font=small,skip=3pt]{caption} % Minder ruimte tussen figuur/table en ondertitel. Ondertitel klein
\usepackage{capt-of}
\usepackage{indentfirst}
\setlength{\parindent}{0.7cm}
\usepackage{enumitem} % Laat enumerate werken met letters
\usepackage{url}
\usepackage{lipsum}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
% Prints a trailing space in a smart way.
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{xcolor}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of "TeX Unbound" for suggested values.
% See pp. 199-200 of Lamport's "LaTeX" book for details.
%   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.9}	% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\textfraction}{0.1}	% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.8}	% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\setcounter{secnumdepth}{3}

\newcommand{\tthdump}[1]{#1}

\newcommand{\openepigraph}[2]{
  \begin{fullwidth}
  \sffamily\large
    \begin{doublespace}
      \noindent\allcaps{#1}\\ % epigraph
      \noindent\allcaps{#2} % author
    \end{doublespace}
  \end{fullwidth}
}


\usepackage{makeidx}
\makeindex

\title{An Introduction to Statisical Learning - own work}
\author{Jan Trommelmans}

\begin{document}
\SweaveOpts{concordance=TRUE,prefix.string=ITSL}
\setkeys{Gin}{width=1.1\marginparwidth} %% Sweave

<<echo=FALSE>>=
library(tidyverse)
library(broom)
library(ISLR)
library(gridExtra)
library(plot3D)
@

% Setting the ggplot theme:
<<echo=FALSE>>=
JT.theme <- theme(panel.border = element_rect(fill = NA, colour = "gray10"),
                  panel.background = element_blank(),
                  panel.grid.major = element_line(colour = "gray85"),
                  panel.grid.minor = element_line(colour = "gray85"),
                  panel.grid.major.x = element_line(colour = "gray85"),
                  axis.text = element_text(size = 8 , face = "bold"),
                  axis.title = element_text(size = 9 , face = "bold"),
                  plot.title = element_text(size = 12 , face = "bold"),
                  strip.text = element_text(size = 8 , face = "bold"),
                  strip.background = element_rect(colour = "black"),
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 9 , face = "bold"),
                  legend.background = element_rect(fill = "white"),
                  legend.key = element_rect(fill = "white"))
@

% Functions

\frontmatter
\chapter*{Introduction to Statistical Learning - own work}

\mainmatter
\chapter{Introduction}

\section{Overview of Statistical Learning}

\subsection{A regression problem: Wage Data}
Continuous reponse variable (wage) with three independent variables: age (continous), year (discrete integer), education level (factor). A \emph{regression} problem. The graphs show a non-linear relationship with ''age", a linear relation with ''year"  and a dependence on the factor ''education level". But all variables show a lot of variation.
<<label=1Wage,fig=TRUE,include=FALSE, echo=FALSE>>=
p1 <- ggplot(data=Wage, aes(x = age, y = wage)) +
  geom_point(alpha=0.1) +
  geom_smooth() +
  labs(x="Age", y="Wage") +
  JT.theme
p2 <- ggplot(data=Wage, aes(x = year, y = wage)) +
  geom_point(alpha=0.1) +
  geom_smooth(method=lm) +
  labs(x="Year", y="Wage") +
  JT.theme
p3 <- ggplot(data=Wage, aes(x = education, y = wage)) +
  geom_boxplot(aes(colour=education)) +
  labs( x="Education level", y="Wage") +
  scale_x_discrete(labels = c('1','2','3', '4', '5')) +
  theme(legend.position="none") +
  JT.theme
grid.arrange(p1, p2, p3, nrow=1)
@

\begin{figure}
\includegraphics[width=0.85\textwidth]{ITSL-1Wage}
\caption{Relations between Wage and main predictors}
\label{fig:1Wage}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\subsection{A classification problem: Stock Market Data}
A categorical reponse variable (increase of decrease of the index) with independent variable: the x days' percentage changes of the index (x=1, 2, 3). A \emph{classification} problem. 

<<label=1Smarket,fig=TRUE,include=FALSE, echo=FALSE>>=
p1 <- ggplot(data=Smarket) +
  geom_boxplot(aes(x=Direction, y= Lag1, colour=Direction)) +
   theme(legend.position="none") +
  labs(title="Yesterday", x="Today's Direction", y="Percentage change in S&P") +
  JT.theme
p2 <- ggplot(data=Smarket) +
  geom_boxplot(aes(x=Direction, y= Lag2, colour=Direction)) +
   theme(legend.position="none") +
  labs(title="Two Days Previous", x="Today's Direction", y="Percentage change in S&P") +
  JT.theme
p3 <- ggplot(data=Smarket) +
  geom_boxplot(aes(x=Direction, y= Lag3, colour=Direction)) +
   theme(legend.position="none") +
  labs(title="Three Days Previous", x="Today's Direction", y="Percentage change in S&P") +
  JT.theme
grid.arrange(p1, p2, p3, nrow=1)
@

\begin{figure}
\includegraphics[width=1\textwidth]{ITSL-1Smarket}
\caption{Classification based on previous change}
\label{fig:1Smarket}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\subsection{A clustering problem: Gene Expression Data (NCI60)}
Only input variables. We are not trying to predict an outcome but are looking for similarities. 

<<label=1NCI60,fig=TRUE,include=FALSE, echo=FALSE>>=
nci.labs <- NCI60$labs
nci.data <- NCI60$data
table(nci.labs)
pr.out <- prcomp(nci.data, scale=TRUE)
Cols = function(vec) {
  cols <- rainbow(length(unique(vec)))
  return(cols[as.numeric(as.factor(vec))])
}
par(mfrow=c(1,2))
plot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19, xlab="Z1", ylab="Z2")
plot(pr.out$x[,c(1,3)], col=Cols(nci.labs), pch=19, xlab="Z1", ylab="Z3")
par(mfrow=c(1,1))
@

\begin{figure}
\includegraphics[width=1\textwidth]{ITSL-1NCI60}
\caption{Clustering based on principal component analysis}
\label{fig:1NCI60}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\chapter{Statistical Learning}

\section{What is statistical learning}

In general: A \emph{response}, \emph{dependent}, \emph{output} variable $Y$ is influenced by a number of \emph{predictor}, \emph{independent}, \emph{input} variables $X_{i}$. We \emph{assume} that the relationschip between $Y$ and the $X_{i}$ can be written as:
\begin{equation}
Y=f(X_{i}) + \epsilon
\end{equation}

where $f(X_{i})$ is an, unknown, but fixed function and $\epsilon$ is a random error term. The function $f(X_{i})$ represent the \emph{systematic information} that the variables $X_{i}$ give about $Y$.

<<echo=FALSE>>=
# Loading the Advertising data
Advertising <- read.csv("data/Advertising.csv", header=TRUE, sep=",")
@

<<label=2Advertising,fig=TRUE,include=FALSE, echo=FALSE>>=
# Making the graphs
ggplot(data=Advertising, aes(x=TV, y= sales)) +
  geom_point(shape=21, color="Red") +
  geom_smooth(method=lm, se=FALSE) +
  JT.theme -> p1
ggplot(data=Advertising, aes(x=radio, y= sales)) +
  geom_point(shape=21, color="Red") +
  geom_smooth(method=lm, se=FALSE) +
  JT.theme -> p2
ggplot(data=Advertising, aes(x=newspaper, y= sales)) +
  geom_point(shape=21, color="Red") +
  geom_smooth(method=lm, se=FALSE) +
  JT.theme -> p3
grid.arrange(p1, p2, p3, nrow=1)
@

\begin{marginfigure}[-5cm]
\includegraphics[width=1\textwidth]{ITSL-2Advertising}
\caption{The \textcolor{red}{Advertising} data set. The plot displays \textbf{sales} as a function of the advertising budget (in thousands of dollars) for adds on TV, radio and in newspapers}
\label{fig:2Advertising}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

In the \textcolor{red}{\textbf{Advertising}} data set, sales ($Y$) are influenced by the amount we spend on advertising in TV ($X_{1}$), on the radio ($X_{2}$) and in the newspapers ($X_{3}$). Figure~\ref{fig:2Advertising} shows simple least squares fits of the dependent variable $Y$ to the variables $X_{1}$, $X_{2}$ and $X_{3}$.

<<echo=FALSE>>=
# Loading Income1 data set
Income1 <- read.csv("data/Income1.csv", header=TRUE, sep=",")
# Guessing a 3th degree polynomial with (from the graph) a value of about 20 for ''years of education"=10, a value of 80 for ''years of education=22, an first derivatives zero at start and end
Income1$f <- 214.44 -45.83*Income1$Education +3.333*(Income1$Education)^2 -0.0694*(Income1$Education)^3
@

The functional relationship is not necessary linear. Figure~\ref{fig:2Income1} gives an example where \textit{Income} is related to \textit{Years of education}.

<<label=2Income1,fig=TRUE,include=FALSE, echo=FALSE>>=
# Making the graphs
ggplot(data=Income1, aes(x=Education, y= Income)) +
  geom_point(shape=21, color="Red") +
  JT.theme -> p1
ggplot(data=Income1, aes(x=Education)) +
  geom_point(aes(y = Income), shape=21, color="Red") +
  geom_line(aes(y =f), color="Black") +
  geom_segment(aes(x=Education, y=Income, xend=Education, yend=f)) +
  JT.theme -> p2
grid.arrange(p1, p2, nrow=1)
@

\begin{marginfigure}
\includegraphics[width=1\textwidth]{ITSL-2Income1}
\caption{The \textcolor{red}{Income} data set. The plot displays \textbf{Income} as a function of the number of years of education. The right hand side gives a model and the error for each observation}
\label{fig:2Income1}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

When we include a second independent variable $X_{2}=Seniority$ we can still give a graphical representation in a threedimensional plot (Figure~\ref{fig:2Income2}).

<<echo=FALSE>>=
# Loading Income2 data set
Income2 <- read.csv("data/Income2.csv", header=TRUE, sep=",")
x <- Income2$Education
y <- Income2$Seniority
z <- Income2$Income
@

<<label=2Income2,fig=TRUE,include=FALSE, echo=FALSE>>=
xyz.fit <- lm(z ~ x + y)
x.pred <- seq(min(x), max(x), length.out = 50)
y.pred <- seq(min(y), max(y), length.out = 50)
xy <- expand.grid(x = x.pred, y = y.pred)
z.pred <- matrix(predict(xyz.fit, newdata = xy), 
                 nrow = 50, ncol = 50)
fitpoints <- predict(xyz.fit)
scatter3D(x, y, z, 
          bt = "b2", # box type
          pch = 21, cex = 0.7, col="red", # shape, size , color of data points
          theta = 25, phi = 20, # viewing angel horiz and vert
          ticktype = "detailed", # detailed ticks on axis
          xlab = "Education", # label x-axis
          ylab = "Seniority", # label y-axis
          zlab = "Income",  # label z-axis
          surf = list(x = x.pred, y = y.pred, z = z.pred,  # coordinates of surface
                      facets = FALSE, # coloring of the surface facets
                      fit=fitpoints, # drax line from surface to data point
                      col=gg.col(1,0.5)), # color pattern (1 = only one color) and alpha value
          main = "", # main title
          colkey = FALSE) # no legend
@

\begin{figure}
\includegraphics[width=0.7\textwidth]{ITSL-2Income2}
\caption{The \textcolor{red}{Income} data set. The 3D-plot displays \textbf{Income} as a function of the number of years of education and seniority.}
\label{fig:2Income2}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\newpage
\subsection{Why estimate the function $f$?}

Once the function $f$ is known we can use it to predict values of the dependent variable $Y$ for given values of the independent variables $X_{i}$ (as long as we stay within the range of $X_{i}$-values for which $f$ is derived!).

\begin{equation}
  \hat{Y}=\hat{f}(X_{i})
\end{equation}

Usually we do not know $f$ exactly, but an approximation of $f$ which we call $\hat{f}$. The accuracy of $\hat{Y}$ depends on two quantities:

\begin{enumerate}
  \item the \emph{reducible} error: this is the error that can be minimised when $\hat{f}$ comes closer to $f$
  \item the \emph{irreducible} error: this is the unknown $\epsilon$ due to unmeasured variables or unknown variables
\end{enumerate}

\newthought{For Prediction} purposes we are not really interested in the actual mathematical form of $\hat{f}$, but only in its usefulness to predict the output $Y$. Essentially: $\hat{f}$ is treated like a \emph{black box}.

\newthought{For Inference} we do want to know the mathematical nature of $\hat{f}$ because we want a better understanding of the model:
\begin{itemize}
  \item which predictors are important?
  \item what is the relationship between the response variable and each of the predictors? Does it increase or decrease?
  \item can the relationship be expressed in a linear way or do we need something more complex?
\end{itemize}

Functions that give more accurate predictions can become opaque and the relation between the dependent variable and the predictors cannot be felt intuitively any more.

\subsection{How to estimate $f$?}

We start with \emph{observations}: a set of n data points, which we call the \emph{training data}. Some notation:
\begin{itemize}
  \item $p$ is the number of independent variables, $n$ is the number of observations
  \item $x_{ij}$ is the $i^{th}$ observation of predictor $x_{j}$
  \item $y_{i}$ is the corresponding value of the output
  \item the training data is $\{ (x_{1}, y_{1}), (x_{2}, y_{2}) \ldots (x_{n}, y_{n}) \}$ with $x_{i}=(x_{i1}, x_{i2} \ldots x_{ip})^{T}$
\end{itemize}

The methods to find $\hat{f}$ are either \emph{parametric} or \emph{non-parametric}.

\newthought{Parametric methods} use a two-step approach:
\begin{enumerate}
  \item assume the shape of $f$:
    \begin{equation}
      f(X) = \beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + \ldots + \beta_{p}X_{p}
    \end{equation}
    This choice (a simple linearity in $X_{i})$ reduces the problem of finding $f$ to the problem of finding $\beta_{i}$ for $i=1 \ldots p$.
    \item \emph{fit} or \emph{train} the model = estimate the parameters $\beta_{i}$ for $i=1 \ldots p$. There are different methods: \emph{ordinary least squares} or \emph{maximise the log-likelihood function}
\end{enumerate}

The advantage of the parametric approach is that it is simple to do. The disadvantage is that the result can be markedly different from reality. Adding more and more parametes can improve the model, but it leads to \emph{overfitting} which makes the model follow the \emph{noise} instead of the signal.

Figure~\ref{fig:2Income2} assumes a linear relation of Income with Education and Seniority. But it does not have the curvature that seems to be in the data. A non-linear function might do better.

<<label=2Income2par,fig=TRUE,include=FALSE, echo=FALSE>>=
scatter3D(x, y, z, 
          bt = "b2", # box type
          pch = 21, cex = 0.7, col="red", # shape, size , color of data points
          theta = 25, phi = 20, # viewing angel horiz and vert
          ticktype = "detailed", # detailed ticks on axis
          xlab = "Education", # label x-axis
          ylab = "Seniority", # label y-axis
          zlab = "Income",  # label z-axis
          surf = list(x = x.pred, y = y.pred, z = z.pred,  # coordinates of surface
                      facets = FALSE, # coloring of the surface facets
                      fit=fitpoints, # drax line from surface to data point
                      col=gg.col(1,0.5)), # color pattern (1 = only one color) and alpha value
          main = "Parametric function: a linear relationship without interaction", # main title
          colkey = FALSE) # no legend
@

\begin{figure}
\includegraphics[width=0.7\textwidth]{ITSL-2Income2par}
\caption{The \textcolor{red}{Income} data set. The 3D-plot displays \textbf{Income} as a function of the number of years of education and seniority.}
\label{fig:2Income2par}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\newthought{Non-parametric models} do not make any assumption about the mathematical form of $f$. \emph{splines} are an example of a non-parametric solution. It does not impose a pre-specified model on $f$. On the other hand: it does not supply any symbolic representation of $f$ either. Making the spline smoother and smoother will in the end give us a perfect fit with the observations, but also with the noise ($\epsilon$) that is always present. This is overfitting.

The R package \textbf{rms} has functions that calculate a spline surface through the data points. It also has drawing functions, but it is better to transform the results into the data-format needed by 3D-drawing package \textbf{plot3D}.

<<label=2Income2nonpar,fig=TRUE,include=FALSE, echo=FALSE>>=
library(rms)
# Making the spline model with package rms
att <- Income2[c('Education','Seniority','Income')]
add <- datadist(att)
options(datadist="add")
mdl <- ols( Income ~ rcs(Education,4)*rcs(Seniority,4) ,data=att)
# Using this model we calculate the predicted value for a grid of np point on the x-axis and np-point on the y-axis
np <- 75 # number of points to predict
pred.rms <- Predict(mdl, 'Education','Seniority', np=np)
# Getting the information form the spline-model that the plot3D package needs to make the graph
x.pred.sp <- unique(pred.rms$Education)
y.pred.sp <- unique(pred.rms$Seniority)
z.pred.sp <- matrix(pred.rms$yhat, nrow=np, ncol=np)
# Using the plot3D package to make the 3D drawing
fitpoints <- predict(mdl)
scatter3D(x, y, z,
          bt = "b2", # box type
          pch = 21, cex = 0.7, col="red", # shape, size , color of data points
          theta = 25, phi = 20, # viewing angel horiz and vert
          ticktype = "detailed", # detailed ticks on axis
          xlab = "Education", # label x-axis
          ylab = "Seniority", # label y-axis
          zlab = "Income",  # label z-axis
          surf = list(x = x.pred.sp, y = y.pred.sp, z = z.pred.sp,  # coordinates of surface
                      facets = FALSE, # coloring of the surface facets
                      fit=fitpoints, # drax line from surface to data point
                      col=gg.col(1,0.4)), # color pattern (1 = only one color) and alpha value
          main = "Non-parametric function: a spline through the data points", # main title
          colkey = FALSE) # no legend
@

\begin{figure}
\includegraphics[width=0.7\textwidth]{ITSL-2Income2nonpar}
\caption{The \textcolor{red}{Income} data set. The 3D-plot displays \textbf{Income} as a spline surfact based on the number of years of education and seniority.}
\label{fig:2Income2nonpar}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

Using the non-parametric methods requires a good understanding of the way splines are calculated. The choice of the spline characteristics can easily lead to under- or overfitting (Figure~\ref{fig:2Income2under} and Figure~\ref{fig:2Income2over}).

<<label=2Income2under,fig=TRUE,include=FALSE, echo=FALSE>>=
mdl <- ols( Income ~ rcs(Education,3)*rcs(Seniority,3) ,data=att)
# Using this model we calculate the predicted value for a grid of np point on the x-axis and np-point on the y-axis
np <- 75 # number of points to predict
pred.rms <- Predict(mdl, 'Education','Seniority', np=np)
# Getting the information form the spline-model that the plot3D package needs to make the graph
x.pred.sp <- unique(pred.rms$Education)
y.pred.sp <- unique(pred.rms$Seniority)
z.pred.sp <- matrix(pred.rms$yhat, nrow=np, ncol=np)
# Using the plot3D package to make the 3D drawing
fitpoints <- predict(mdl)
scatter3D(x, y, z,
          bt = "b2", # box type
          pch = 21, cex = 0.7, col="red", # shape, size , color of data points
          theta = 25, phi = 20, # viewing angel horiz and vert
          ticktype = "detailed", # detailed ticks on axis
          xlab = "Education", # label x-axis
          ylab = "Seniority", # label y-axis
          zlab = "Income",  # label z-axis
          surf = list(x = x.pred.sp, y = y.pred.sp, z = z.pred.sp,  # coordinates of surface
                      facets = FALSE, # coloring of the surface facets
                      fit=fitpoints, # drax line from surface to data point
                      col=gg.col(1,0.4)), # color pattern (1 = only one color) and alpha value
          main = "Non-parametric function: underfitting", # main title
          colkey = FALSE) # no legend
@

<<label=2Income2over,fig=TRUE,include=FALSE, echo=FALSE>>=
mdl <- ols( Income ~ rcs(Education,5)*rcs(Seniority,5) ,data=att)
# Using this model we calculate the predicted value for a grid of np point on the x-axis and np-point on the y-axis
np <- 75 # number of points to predict
pred.rms <- Predict(mdl, 'Education','Seniority', np=np)
# Getting the information form the spline-model that the plot3D package needs to make the graph
x.pred.sp <- unique(pred.rms$Education)
y.pred.sp <- unique(pred.rms$Seniority)
z.pred.sp <- matrix(pred.rms$yhat, nrow=np, ncol=np)
# Using the plot3D package to make the 3D drawing
fitpoints <- predict(mdl)
scatter3D(x, y, z,
          bt = "b2", # box type
          pch = 21, cex = 0.7, col="red", # shape, size , color of data points
          theta = 25, phi = 20, # viewing angel horiz and vert
          ticktype = "detailed", # detailed ticks on axis
          xlab = "Education", # label x-axis
          ylab = "Seniority", # label y-axis
          zlab = "Income",  # label z-axis
          surf = list(x = x.pred.sp, y = y.pred.sp, z = z.pred.sp,  # coordinates of surface
                      facets = FALSE, # coloring of the surface facets
                      fit=fitpoints, # drax line from surface to data point
                      col=gg.col(1,0.4)), # color pattern (1 = only one color) and alpha value
          main = "Non-parametric function: overfitting", # main title
          colkey = FALSE) # no legend
@

\begin{figure}
\includegraphics[width=0.7\textwidth]{ITSL-2Income2under}
\caption{The \textcolor{red}{Income} data set. Effects of underfitting}
\label{fig:2Income2under}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\begin{figure}
\includegraphics[width=0.7\textwidth]{ITSL-2Income2over}
\caption{The \textcolor{red}{Income} data set. Effects of overfitting}
\label{fig:2Income2over}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}
\newpage
\textbf{Thanks} \\
\medskip
R Core Team (2018). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.
\medskip
<<>>=
sessionInfo()
@

\end{document}